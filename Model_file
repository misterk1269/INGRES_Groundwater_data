# INGRES AI-Driven ChatBot with Gemini 2.5 Flash Integration
# Complete Implementation for Jupyter Notebook

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
import re
from datetime import datetime
import joblib
import json
import requests
import google.generativeai as genai
from typing import Dict, List, Any, Optional
warnings.filterwarnings('ignore')

# Configure Gemini API
GEMINI_API_KEY = "AIzaSyBOrYGa8Aer07t_eXeNimb-VmqppgVZWEU"
genai.configure(api_key=GEMINI_API_KEY)

# Set style for better visualizations
plt.style.use('default')
sns.set_palette("husl")

class INGRESChatBot:
    """
    AI-Driven ChatBot for INGRES - India Ground Water Resource Estimation System
    Integrates ML predictions with Gemini 2.5 Flash for intelligent conversations
    """
    
    def __init__(self, data_path=None):
        """Initialize the ChatBot with data, models, and Gemini integration"""
        self.data = None
        self.models = {}
        self.scalers = {}
        self.encoders = {}
        self.feature_columns = []
        self.gemini_model = None
        self.conversation_history = []
        
        # Initialize Gemini model
        self._initialize_gemini()
        
        if data_path:
            self.load_data(data_path)
    
    def _initialize_gemini(self):
        """Initialize Gemini 2.5 Flash model"""
        try:
            self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
            print("‚úÖ Gemini 2.5 Flash initialized successfully!")
        except Exception as e:
            print(f"‚ùå Error initializing Gemini: {str(e)}")
    
    def load_data(self, data_path):
        """Load and preprocess the groundwater data"""
        try:
            import pandas as pd
            from io import StringIO
    
            # --- Load CSV ---
            if data_path.startswith('http'):
                import requests
                s = requests.get(data_path).content
                s_clean = s.decode('utf-8', errors='replace')
                self.data = pd.read_csv(StringIO(s_clean))
            else:
                with open(data_path, "rb") as f:
                    content = f.read()
                s_clean = content.decode('utf-8', errors='replace')
                self.data = pd.read_csv(StringIO(s_clean))
    
            # --- Clean column names ---
            self.data.columns = (
                self.data.columns
                .str.replace(u'\xa0', ' ', regex=False)  # remove NBSP
                .str.strip()                             # trim spaces
                .str.replace(r'\s+', ' ', regex=True)    # normalize multiple spaces
            )
    
            # Rename rainfall column safely
            if "Rainfall (mm) " in self.data.columns:
                self.data.rename(columns={"Rainfall (mm) ": "Rainfall_mm"}, inplace=True)
            elif "Rainfall (mm)" in self.data.columns:
                self.data.rename(columns={"Rainfall (mm)": "Rainfall_mm"}, inplace=True)
    
            # Clean Category column
            if 'Category' in self.data.columns:
                self.data['Category'] = (
                    self.data['Category']
                    .astype(str)
                    .str.replace("ÔøΩ", "-", regex=False)
                    .str.strip()
                )
    
            print(f"‚úÖ Data loaded successfully! Shape: {self.data.shape}")
            print(f"üìä Final Columns: {list(self.data.columns)}")
    
            # --- Preprocess and train models ---
            self._preprocess_data()
            self._train_models()
    
        except Exception as e:
            print(f"‚ùå Error loading data: {str(e)}")

    
    def _preprocess_data(self):
        """Preprocess the groundwater data"""
        # Handle missing values
        numeric_columns = self.data.select_dtypes(include=[np.number]).columns
        self.data[numeric_columns] = self.data[numeric_columns].fillna(self.data[numeric_columns].median())
        
        # Create additional features
        self.data['Recharge_Extraction_Ratio'] = (
            self.data['Ground Water Recharge (ham)'] / 
            (self.data['Ground Water Extraction (ham)'] + 1)
        )
        
        self.data['Water_Stress_Index'] = (
            self.data['Ground Water Extraction (ham)'] / 
            (self.data['Annual Extractable Ground Water Resources (ham)'] + 1)
        )
        
        self.data['Sustainability_Score'] = (
            (self.data['Ground Water Recharge (ham)'] - self.data['Ground Water Extraction (ham)']) /
            (self.data['Annual Extractable Ground Water Resources (ham)'] + 1)
        )
        
        # Encode categorical variables
        le_state = LabelEncoder()
        le_category = LabelEncoder()
        
        self.data['State_Encoded'] = le_state.fit_transform(self.data['State'])
        self.data['Category_Encoded'] = le_category.fit_transform(self.data['Category'])
        
        self.encoders['state'] = le_state
        self.encoders['category'] = le_category
        
        # Define feature columns for modeling
        self.feature_columns = [
            'State_Encoded', 'Year', 'Rainfall_mm', 
            'Ground Water Recharge (ham)', 'Natural Discharges (ham)',
            'Annual Extractable Ground Water Resources (ham)',
            'Recharge_Extraction_Ratio', 'Water_Stress_Index'
        ]
        
        print("‚úÖ Data preprocessing completed!")
    
    from sklearn.preprocessing import StandardScaler

    def _train_models(self):
        self.models = {}
        self.scalers = {}   # ‚úÖ dict reset
        errors = []
    
        try:
            # --- Extraction predictor ---
            df1 = self.data.dropna(subset=[
                'Ground Water Extraction (ham)',
                'Rainfall_mm',
                'Ground Water Recharge (ham)',
                'Annual Extractable Ground Water Resources (ham)'
            ])
            X1 = df1[['Rainfall_mm', 'Ground Water Recharge (ham)',
                      'Annual Extractable Ground Water Resources (ham)']]
            y1 = df1['Ground Water Extraction (ham)']
    
            self.scalers['extraction'] = StandardScaler()   # ‚úÖ dict me save
            X1_scaled = self.scalers['extraction'].fit_transform(X1)
    
            from sklearn.linear_model import LinearRegression
            model1 = LinearRegression()
            model1.fit(X1_scaled, y1)
            self.models['extraction_predictor'] = model1
            print(f"‚úÖ Extraction Model R¬≤: {model1.score(X1_scaled, y1):.3f}")
        except Exception:
            errors.append("extraction_predictor")
    
        try:
            # --- SGE predictor ---
            df2 = self.data.dropna(subset=[
                'SGE(%)',
                'Ground Water Extraction (ham)',
                'Annual Extractable Ground Water Resources (ham)'
            ])
            X2 = df2[['Ground Water Extraction (ham)',
                      'Annual Extractable Ground Water Resources (ham)']]
            y2 = df2['SGE(%)']
    
            self.scalers['sge'] = StandardScaler()   # ‚úÖ dict me save
            X2_scaled = self.scalers['sge'].fit_transform(X2)
    
            model2 = LinearRegression()
            model2.fit(X2_scaled, y2)
            self.models['sge_predictor'] = model2
            print(f"‚úÖ SGE Model R¬≤: {model2.score(X2_scaled, y2):.3f}")
        except Exception:
            errors.append("sge_predictor")
    
        try:
            # --- Category classifier ---
            df3 = self.data.dropna(subset=[
                'Category',
                'SGE(%)',
                'Ground Water Extraction (ham)',
                'Ground Water Recharge (ham)'
            ])
            X3 = df3[['SGE(%)', 'Ground Water Extraction (ham)', 'Ground Water Recharge (ham)']]
            y3 = df3['Category']
    
            self.scalers['category'] = StandardScaler()   # ‚úÖ dict me save
            X3_scaled = self.scalers['category'].fit_transform(X3)
    
            from sklearn.ensemble import RandomForestClassifier
            model3 = RandomForestClassifier(random_state=42)
            model3.fit(X3_scaled, y3)
            self.models['category_classifier'] = model3
            print("‚úÖ Category Classifier trained successfully!")
        except Exception:
            errors.append("category_classifier")
    
        if errors:
            print(f"‚ùå Error training models: {errors}")

    def get_data_summary(self, state=None, year=None, category=None):
        """Get comprehensive data summary with filters"""
        try:
            df = self.data.copy()
            
            # Apply filters
            if state:
                df = df[df['State'].str.contains(state, case=False, na=False)]
            if year:
                df = df[df['Year'] == year]
            if category:
                df = df[df['Category'].str.contains(category, case=False, na=False)]
            
            if df.empty:
                return "No data found for the specified criteria."
            
            summary = {
                'total_records': len(df),
                'states_covered': df['State'].nunique(),
                'year_range': f"{df['Year'].min()} - {df['Year'].max()}",
                'avg_rainfall': df['Rainfall_mm'].mean(),
                'avg_recharge': df['Ground Water Recharge (ham)'].mean(),
                'avg_extraction': df['Ground Water Extraction (ham)'].mean(),
                'avg_sge': df['SGE(%)'].mean(),
                'category_distribution': df['Category'].value_counts().to_dict(),
                'critical_areas': len(df[df['Category'].isin(['Critical', 'Over-Exploited'])]),
                'safe_areas': len(df[df['Category'] == 'Safe'])
            }
            
            return summary
        except Exception as e:
            return f"Error generating summary: {str(e)}"
    
    def predict_groundwater_metrics(self, state, year, rainfall, recharge, natural_discharge, extractable_resources):
        try:
            # Ensure models exist
            for key in ['extraction_predictor', 'sge_predictor', 'category_classifier']:
                if key not in self.models:
                    raise ValueError(f"{key} model not trained")
            
            # Feature sets for each model
            X_extraction = [[rainfall, recharge, extractable_resources]]
            X_sge = [[0, extractable_resources]]  # extraction ke baad fill karenge
            X_category = [[0, 0, recharge]]       # extraction + sge ke baad fill karenge
    
            # Extraction prediction
            X_extraction_scaled = self.scalers['extraction'].transform(X_extraction)
            predicted_extraction = self.models['extraction_predictor'].predict(X_extraction_scaled)[0]
    
            # Update for SGE
            X_sge = [[predicted_extraction, extractable_resources]]
            X_sge_scaled = self.scalers['sge'].transform(X_sge)
            predicted_sge = self.models['sge_predictor'].predict(X_sge_scaled)[0]
    
            # Update for Category
            X_category = [[predicted_sge, predicted_extraction, recharge]]
            X_category_scaled = self.scalers['category'].transform(X_category)
            predicted_category = self.models['category_classifier'].predict(X_category_scaled)[0]
    
            return {
                'predicted_extraction': round(float(predicted_extraction), 2),
                'predicted_sge': round(float(predicted_sge), 2),
                'predicted_category': predicted_category,
                'water_stress_level': 'High' if predicted_sge > 70 else 'Medium' if predicted_sge > 40 else 'Low'
            }
    
        except Exception as e:
            return f"Error making prediction: {str(e)}"

    def create_visualization(self, chart_type, **kwargs):
        """Create interactive visualizations using Plotly"""
        try:
            if chart_type == 'state_wise_sge':
                fig = px.box(self.data, x='State', y='SGE(%)', 
                            title='State-wise Stage of Groundwater Extraction Distribution',
                            color='Category')
                fig.update_xaxes(tickangle=45)
                
            elif chart_type == 'yearly_trend':
                yearly_data = self.data.groupby('Year').agg({
                    'Ground Water Extraction (ham)': 'mean',
                    'Ground Water Recharge (ham)': 'mean',
                    'SGE(%)': 'mean'
                }).reset_index()
                
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                fig.add_trace(go.Scatter(x=yearly_data['Year'], 
                                       y=yearly_data['Ground Water Extraction (ham)'],
                                       name='Extraction'), secondary_y=False)
                fig.add_trace(go.Scatter(x=yearly_data['Year'], 
                                       y=yearly_data['Ground Water Recharge (ham)'],
                                       name='Recharge'), secondary_y=False)
                fig.add_trace(go.Scatter(x=yearly_data['Year'], 
                                       y=yearly_data['SGE(%)'],
                                       name='SGE %'), secondary_y=True)
                fig.update_layout(title='Yearly Groundwater Trends')
                
            elif chart_type == 'category_distribution':
                category_counts = self.data['Category'].value_counts()
                fig = px.pie(values=category_counts.values, names=category_counts.index,
                           title='Groundwater Category Distribution')
                
            elif chart_type == 'rainfall_vs_recharge':
                fig = px.scatter(self.data, x='Rainfall_mm', y='Ground Water Recharge (ham)',
                               color='Category', size='SGE(%)', 
                               title='Rainfall vs Groundwater Recharge by Category')
                
            else:
                return None
                
            fig.update_layout(height=500)
            return fig
            
        except Exception as e:
            print(f"Error creating visualization: {str(e)}")
            return None
    
    def _generate_context_for_gemini(self, query):
        """Generate context about INGRES data for Gemini"""
        data_context = f"""
        You are an AI assistant for INGRES (India Ground Water Resource Estimation System).
        
        Current database contains:
        - {len(self.data)} assessment records
        - Coverage: {self.data['State'].nunique()} Indian states
        - Time period: {self.data['Year'].min()} to {self.data['Year'].max()}
        - Categories: {', '.join(self.data['Category'].unique())}
        
        Key metrics tracked:
        - Rainfall_mm
        - Ground Water Recharge (ham)
        - Natural Discharges (ham)  
        - Annual Extractable Ground Water Resources (ham)
        - Ground Water Extraction (ham)
        - SGE (Stage of Groundwater Extraction) %
        - Category (Safe, Semi-Critical, Critical, Over-Exploited)
        
        Latest data summary:
        - Average SGE: {self.data['SGE(%)'].mean():.1f}%
        - Critical/Over-exploited areas: {len(self.data[self.data['Category'].isin(['Critical', 'Over-Exploited'])])} units
        - Safe areas: {len(self.data[self.data['Category'] == 'Safe'])} units
        
        User query: {query}
        
        Provide helpful, accurate information about groundwater resources in India. 
        Be specific with numbers when available. If asked about predictions or analysis, 
        mention that the system can provide ML-based forecasts.
        """
        
        return data_context
    
    def chat_with_gemini(self, user_query):
        """Process user query with Gemini 2.5 Flash"""
        try:
            # Add query to conversation history
            self.conversation_history.append({"role": "user", "content": user_query})
            
            # Generate context
            context = self._generate_context_for_gemini(user_query)
            
            # Get response from Gemini
            response = self.gemini_model.generate_content(context)
            
            # Add response to history
            self.conversation_history.append({"role": "assistant", "content": response.text})
            
            return response.text
            
        except Exception as e:
            return f"Sorry, I encountered an error: {str(e)}. Please try again."
    
    def process_query(self, query):
        """Main query processing function with intelligent routing"""
        query_lower = query.lower()
        
        # Check for specific data requests
        if any(word in query_lower for word in ['predict', 'forecast', 'estimate']):
            return "To make predictions, use the predict_groundwater_metrics() function with specific parameters."
        
        elif any(word in query_lower for word in ['visualize', 'chart', 'graph', 'plot']):
            return "To create visualizations, use the create_visualization() function with chart type."
        
        elif any(word in query_lower for word in ['summary', 'overview', 'statistics']):
            summary = self.get_data_summary()
            gemini_response = self.chat_with_gemini(f"Explain this groundwater data summary: {summary}")
            return gemini_response
        
        else:
            # Use Gemini for general queries
            return self.chat_with_gemini(query)
    
    def get_state_analysis(self, state_name):
        """Get detailed analysis for a specific state"""
        try:
            state_data = self.data[self.data['State'].str.contains(state_name, case=False, na=False)]
            
            if state_data.empty:
                return f"No data found for {state_name}"
            
            analysis = {
                'state': state_name,
                'total_assessments': len(state_data),
                'years_covered': sorted(state_data['Year'].unique().tolist()),
                'avg_rainfall': round(state_data['Rainfall_mm'].mean(), 2),
                'avg_sge': round(state_data['SGE(%)'].mean(), 2),
                'category_breakdown': state_data['Category'].value_counts().to_dict(),
                'trend': 'Improving' if state_data.groupby('Year')['SGE(%)'].mean().diff().iloc[-1] < 0 else 'Declining',
                'critical_blocks': len(state_data[state_data['Category'].isin(['Critical', 'Over-Exploited'])])
            }
            
            # Generate Gemini insights
            gemini_insight = self.chat_with_gemini(
                f"Provide insights and recommendations for groundwater management in {state_name} based on this data: {analysis}"
            )
            
            return {
                'data_analysis': analysis,
                'ai_insights': gemini_insight
            }
            
        except Exception as e:
            return f"Error analyzing {state_name}: {str(e)}"
    
    def export_results(self, results, filename):
        """Export analysis results to various formats"""
        try:
            if filename.endswith('.json'):
                with open(filename, 'w') as f:
                    json.dump(results, f, indent=2, default=str)
            elif filename.endswith('.csv'):
                if isinstance(results, dict):
                    pd.DataFrame([results]).to_csv(filename, index=False)
                else:
                    pd.DataFrame(results).to_csv(filename, index=False)
            
            print(f"‚úÖ Results exported to {filename}")
            
        except Exception as e:
            print(f"‚ùå Export error: {str(e)}")

# Initialize and demonstrate the ChatBot
def initialize_ingres_chatbot():
    """Initialize INGRES ChatBot with sample data"""
    
    print("ü§ñ Initializing INGRES AI ChatBot...")
    print("=" * 50)
    
    # Initialize ChatBot
    chatbot = INGRESChatBot()
    
    # Load data from GitHub
    data_url = "https://github.com/misterk1269/INGRES_Groundwater_data/raw/main/final_groundwater_predictions%20(1).csv"
    chatbot.load_data(data_url)
    
    return chatbot

def demo_chatbot_features(chatbot):
    """Demonstrate key ChatBot features"""
    
    print("\nüöÄ INGRES ChatBot Demo")
    print("=" * 50)
    
    # 1. General query with Gemini
    print("\n1. General Query Processing:")
    response = chatbot.process_query("What is the current status of groundwater in India?")
    print(f"ü§ñ Response: {response[:200]}...")
    
    # 2. Data summary
    print("\n2. Data Summary:")
    summary = chatbot.get_data_summary()
    print(f"üìä Summary: {summary}")
    
    # 3. State analysis
    print("\n3. State Analysis:")
    state_analysis = chatbot.get_state_analysis("Gujarat")
    if isinstance(state_analysis, dict):
        print(f"üèõÔ∏è Gujarat Analysis: {state_analysis['data_analysis']}")
    
    # 4. Prediction example
    print("\n4. Groundwater Prediction:")
    prediction = chatbot.predict_groundwater_metrics(
        state="Gujarat", year=2023, rainfall=500, 
        recharge=1000, natural_discharge=200, extractable_resources=1500
    )
    print(f"üîÆ Prediction: {prediction}")
    
    # 5. Create visualization
    print("\n5. Creating Visualizations:")
    fig = chatbot.create_visualization('category_distribution')
    if fig:
        print("üìà Category distribution chart created!")
        # fig.show()  # Uncomment to display
    
    print("\n‚úÖ Demo completed successfully!")

# Main execution
if __name__ == "__main__":
    # Initialize ChatBot
    ingres_bot = initialize_ingres_chatbot()
    
    # Run demo
    demo_chatbot_features(ingres_bot)
    
    print("\n" + "=" * 50)
    print("üéâ INGRES AI ChatBot is ready!")
    print("Available functions:")
    print("- ingres_bot.process_query('your question')")
    print("- ingres_bot.get_state_analysis('state_name')")
    print("- ingres_bot.predict_groundwater_metrics(...)")
    print("- ingres_bot.create_visualization('chart_type')")
    print("- ingres_bot.get_data_summary()")
    print("=" * 50)
